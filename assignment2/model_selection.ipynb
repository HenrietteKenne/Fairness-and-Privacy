{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Private Model Selection.\"\"\"\n",
    "import argparse\n",
    "from glob import glob\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils import get_data_loaders\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.misc import logsumexp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_probs(ndarray_of_probs, name):\n",
    "    if not isinstance(ndarray_of_probs, np.ndarray):\n",
    "        msg = 'ndarray_of_probs should be a np.ndarray. ' + \\\n",
    "                'Make sure to convert from torch.tensor if need be.'\n",
    "        raise ValueError(msg)\n",
    "    if not isinstance(name, str):\n",
    "        raise ValueError('name should be a str')\n",
    "\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    dirname = './figs'\n",
    "    filename = os.path.join(dirname, name) + '.model-selection-probs.png'\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "    fig, ax = plt.subplots()\n",
    "    model_idxs = np.arange(len(ndarray_of_probs))\n",
    "    ax.bar(model_idxs, ndarray_of_probs)\n",
    "    ax.set_xlabel('model idx')\n",
    "    ax.set_ylabel('prob of being selected under Exp Mech')\n",
    "    ax.set_title(name)\n",
    "    ax.set_xticks(model_idxs)\n",
    "    fig.savefig(filename)\n",
    "    return filename\n",
    "\n",
    "\n",
    "def load_models(num_pixels):\n",
    "    \"\"\"Randomly samples k pre-trained models parameters (from the list of ten)\n",
    "    \"\"\"\n",
    "    list_of_model_filenames = glob('./pretrained_models/*.pt')\n",
    "    list_of_model_filenames.sort()\n",
    "    list_of_models = []\n",
    "    for model_filename in list_of_model_filenames:\n",
    "        model = nn.Linear(num_pixels, 1, bias=False)\n",
    "        model.load_state_dict(torch.load(model_filename))\n",
    "        list_of_models.append(model)\n",
    "    return list_of_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_scores(list_of_models, test_loader):\n",
    "    \"\"\"Compute score (performance on private test data) for each model\"\"\"\n",
    "    if not isinstance(list_of_models, list):\n",
    "        raise ValueError('first argument should be a list')\n",
    "    if not isinstance(test_loader, DataLoader):\n",
    "        raise ValueError('second argument should be pytorch data loader')\n",
    "\n",
    "    ############################################################################\n",
    "    # TODO(student)\n",
    "    #\n",
    "    # your code here...\n",
    "    \n",
    "    criterion= nn.BCEWithLogitsLoss()\n",
    "    num_test_examples= len(test_loader.dataset)\n",
    "    liste= np.zeros(len(list_of_models))\n",
    "    k=0\n",
    "    for model in list_of_models:\n",
    "        \n",
    "        losses=0\n",
    "        #loss=0\n",
    "        for i, (images, labels) in enumerate(test_loader):\n",
    "            images = images.reshape(-1, 28*28)\n",
    "            outputs= model(images)\n",
    "            loss= criterion(outputs.squeeze(), labels.float())\n",
    "            losses += loss * (len(images) / float(num_test_examples))\n",
    "            \n",
    "        liste[k]=1.0 - losses\n",
    "        k+=1\n",
    "            \n",
    "    return liste\n",
    "\n",
    "    \n",
    "    \n",
    "def exponential_mechanism(list_of_models, test_loader, epsilon):\n",
    "    \"\"\"Sample from model list, where sampling probability scales with test score\n",
    "    \n",
    "    Return both the sampled model and the sample index\n",
    "    \"\"\"\n",
    "    if not isinstance(list_of_models, list):\n",
    "        raise ValueError('first argument should be a list')\n",
    "    if not isinstance(test_loader, DataLoader):\n",
    "        raise ValueError('second argument should be pytorch data loader')\n",
    "\n",
    "    scores = compute_scores(list_of_models, test_loader)\n",
    "    num_test_examples = len(test_loader.dataset)\n",
    "\n",
    "    ############################################################################\n",
    "    # TODO(student)\n",
    "    #\n",
    "    # your code here..\n",
    "\n",
    "    #sample_probs= np.zeros(len(list_of_models))\n",
    "    #scores= np.array(scores)\n",
    "    sensibility = 2/(num_test_examples)\n",
    "    num = (epsilon*scores)/sensibility\n",
    "    som = logsumexp((epsilon*scores)/sensibility)\n",
    "    \n",
    "    sample_probs = np.array(np.exp(num - som))  \n",
    "    \n",
    "    Proba = np.random.choice(sample_probs)\n",
    "    sampled_idx= np.where(sample_probs == Proba)[0][0]\n",
    "    \n",
    "    sampled_model= list_of_models[sampled_idx]\n",
    "    \n",
    "    # hint: you're exponential mechanism should somehow depend on the number of\n",
    "    # training data in test loader\n",
    "    #\n",
    "    #raise NotImplementedError\n",
    "    ############################################################################\n",
    "\n",
    "    return sampled_model, sampled_idx, sample_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 250\n",
    "SEED = 3771\n",
    "\n",
    "def main(n, epsilon):\n",
    "    loaders, _ = get_data_loaders(SEED, BATCH_SIZE, \n",
    "            num_train=13006, num_test=n)\n",
    "    num_pixels = loaders['train'].dataset.num_pixels\n",
    "    models = load_models(num_pixels)\n",
    "\n",
    "    private_best_model, private_best_model_idx, sample_probs \\\n",
    "            = exponential_mechanism(models, loaders['test'], epsilon)\n",
    "\n",
    "    print('selected model', private_best_model_idx)\n",
    "    name = 'eps={},n={}'.format(epsilon, n)\n",
    "    filename = plot_probs(sample_probs, name)\n",
    "    print('see plot at', filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "arguments and main function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected model 9\n",
      "see plot at ./figs/eps=1,n=2.model-selection-probs.png\n",
      "selected model 8\n",
      "see plot at ./figs/eps=2,n=2.model-selection-probs.png\n",
      "selected model 2\n",
      "see plot at ./figs/eps=4,n=2.model-selection-probs.png\n",
      "selected model 7\n",
      "see plot at ./figs/eps=1,n=10.model-selection-probs.png\n",
      "selected model 8\n",
      "see plot at ./figs/eps=2,n=10.model-selection-probs.png\n",
      "selected model 9\n",
      "see plot at ./figs/eps=4,n=10.model-selection-probs.png\n",
      "selected model 1\n",
      "see plot at ./figs/eps=1,n=100.model-selection-probs.png\n",
      "selected model 4\n",
      "see plot at ./figs/eps=2,n=100.model-selection-probs.png\n",
      "selected model 4\n",
      "see plot at ./figs/eps=4,n=100.model-selection-probs.png\n",
      "selected model 5\n",
      "see plot at ./figs/eps=1,n=1000.model-selection-probs.png\n",
      "selected model 9\n",
      "see plot at ./figs/eps=2,n=1000.model-selection-probs.png\n",
      "selected model 2\n",
      "see plot at ./figs/eps=4,n=1000.model-selection-probs.png\n"
     ]
    }
   ],
   "source": [
    "N = [2,10,100,1000]\n",
    "EPSILON = [1,2,4]\n",
    "\n",
    "for j in N:\n",
    "    for i in EPSILON:\n",
    "        main(j,i)\n",
    "        #print(type(j),type(i))\n",
    "    \n",
    "# TODO(student): sweep over the required values for N and EPSILON and produce \n",
    "#                several plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What score function should we use to compare models on the test set? The score function that we should use to comapre the test set is: 1-loss, because it depend of how good output is for the database."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
